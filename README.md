# Awesome-LLM-Compression

## Pruning

| Year | Conference | Name      | Paper                                                        | Code                                                         |
| ---- | ---------- | --------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 2025 | **ICML**   | SlimLLM   | [Slim: Accurate Structured Pruning for Large Language Models](https://www.arxiv.org/abs/2505.22689) |                                                              |
| 2025 | **ICML**   | DLP       | [DLP: Dynamic Layerwise Pruning in Large Language Models](https://arxiv.org/abs/2505.23807) | [Code](https://github.com/ironartisan/DLP)                   |
| 2025 | **ACL**    | SPRINT    | [Structured Pruning for Diverse Best-of-N Reasoning Optimization](https://www.arxiv.org/abs/2506.03978) | [Code](https://github.com/HieuNT91/attention_pruning)        |
| 2025 | **IJCAI**  | SPRINT    | [Accurate Sublayer Pruning for Large Language Models by Exploiting Latency and Tunability Information](https://www.arxiv.org/abs/2506.03510) | [Code](https://github.com/snudm-starlab/SPRINT)              |
| 2024 | **EMNLP**  |           | [Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization](https://aclanthology.org/2024.emnlp-main.68.pdf) | [Code](https://github.com/LOG-postech/rethinking-LLM-pruning) |
| 2024 | **EMNLP**  | SoBP      | [Structured Optimal Brain Pruning for Large Language Models](https://aclanthology.org/2024.emnlp-main.775.pdf) |                                                              |
| 2024 | **EMNLP**  | PM        | [Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging](https://aclanthology.org/2024.emnlp-main.987.pdf) | [Code](https://github.com/SempraETY/Pruning-via-Merging)     |
| 2024 | **EMNLP**  |           | [Is C4 Dataset Optimal for Pruning? An Investigation of Calibration Data for LLM Pruning](https://aclanthology.org/2024.emnlp-main.1004.pdf) | [Code](https://github.com/abx393/llm-pruning-calibration-data) |
| 2023 | **ICML**   | SparseGPT | [SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot](https://arxiv.org/pdf/2301.00774) | [Code](https://github.com/IST-DASLab/sparsegpt)              |

